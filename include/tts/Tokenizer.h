/**
 * @file Tokenizer.h
 * @brief Text tokenization and pre-tokenized file loader for Chatterbox TTS
 * 
 * Supports two modes:
 * 1. Direct tokenization using HuggingFace tokenizer.json via tokenizers-cpp
 * 2. Loading pre-tokenized binary .tokens files
 */

#pragma once

#include <string>
#include <vector>
#include <cstdint>
#include <optional>
#include <unordered_map>
#include <memory>

// Forward declare tokenizers namespace
namespace tokenizers {
    class Tokenizer;
}

namespace ChatterboxTTS {

/**
 * @brief Token data container
 */
struct TokenData {
    std::vector<int64_t> tokenIds;  ///< Token IDs for the text
    std::string originalText;        ///< Original text (if stored)
    
    bool IsValid() const { return !tokenIds.empty(); }
    size_t Size() const { return tokenIds.size(); }
};

/**
 * @brief Tokenizer file format version
 */
constexpr uint32_t TOKEN_FILE_MAGIC = 0x544B4E53;  // "TKNS"
constexpr uint32_t TOKEN_FILE_VERSION = 1;

/**
 * @brief Binary token file header
 */
#pragma pack(push, 1)
struct TokenFileHeader {
    uint32_t magic;           ///< Magic number (TOKEN_FILE_MAGIC)
    uint32_t version;         ///< File format version
    uint32_t numTokens;       ///< Number of tokens
    uint32_t textLength;      ///< Length of original text (0 if not stored)
    uint32_t reserved[4];     ///< Reserved for future use
};
#pragma pack(pop)

/**
 * @brief HuggingFace tokenizer wrapper using tokenizers-cpp
 * 
 * Loads tokenizer.json files and provides direct text-to-token conversion.
 */
class HFTokenizer {
public:
    HFTokenizer();
    ~HFTokenizer();
    
    // Non-copyable
    HFTokenizer(const HFTokenizer&) = delete;
    HFTokenizer& operator=(const HFTokenizer&) = delete;
    
    // Moveable
    HFTokenizer(HFTokenizer&&) noexcept;
    HFTokenizer& operator=(HFTokenizer&&) noexcept;
    
    /**
     * @brief Load tokenizer from a tokenizer.json file
     * @param path Path to tokenizer.json
     * @return true on success
     */
    bool LoadFromFile(const std::string& path);
    
    /**
     * @brief Load tokenizer from JSON blob in memory
     * @param jsonBlob The JSON content as a string
     * @return true on success
     */
    bool LoadFromJSON(const std::string& jsonBlob);
    
    /**
     * @brief Check if tokenizer is loaded
     */
    bool IsLoaded() const { return m_tokenizer != nullptr; }
    
    /**
     * @brief Encode text to token IDs
     * @param text Input text
     * @return Vector of token IDs
     */
    std::vector<int64_t> Encode(const std::string& text);
    
    /**
     * @brief Decode token IDs back to text
     * @param ids Token IDs
     * @return Decoded text
     */
    std::string Decode(const std::vector<int64_t>& ids);
    
    /**
     * @brief Get vocabulary size
     */
    size_t GetVocabSize() const;
    
    /**
     * @brief Convert token ID to token string
     */
    std::string IdToToken(int32_t id);
    
    /**
     * @brief Convert token string to ID
     * @return Token ID or -1 if not found
     */
    int32_t TokenToId(const std::string& token);
    
    /**
     * @brief Get last error message
     */
    const std::string& GetLastError() const { return m_lastError; }

private:
    std::unique_ptr<tokenizers::Tokenizer> m_tokenizer;
    std::string m_lastError;
};

/**
 * @brief Pre-tokenized file loader
 * 
 * Loads token files generated by the Python tokenization tools.
 * Supports both single-line and batch tokenization formats.
 */
class Tokenizer {
public:
    Tokenizer() = default;
    ~Tokenizer() = default;
    
    /**
     * @brief Load tokens from a binary .tokens file
     * @param path Path to the token file
     * @return TokenData or std::nullopt on failure
     */
    std::optional<TokenData> LoadTokenFile(const std::string& path);
    
    /**
     * @brief Load tokens from a batch .tokens file
     * 
     * Batch files contain multiple tokenized lines with an index.
     * 
     * @param path Path to batch token file
     * @return Map of line index to tokens
     */
    std::unordered_map<int, TokenData> LoadBatchTokenFile(const std::string& path);
    
    /**
     * @brief Load tokens from raw vector (for direct passing)
     * @param tokens Token ID vector
     * @return TokenData
     */
    TokenData CreateTokenData(const std::vector<int64_t>& tokens);
    
    /**
     * @brief Save tokens to binary file
     * @param path Output path
     * @param data Token data to save
     * @return true on success
     */
    bool SaveTokenFile(const std::string& path, const TokenData& data);
    
    /**
     * @brief Get last error message
     */
    const std::string& GetLastError() const { return m_lastError; }
    
    /**
     * @brief Check if a file looks like a valid token file
     */
    static bool IsTokenFile(const std::string& path);
    
private:
    std::string m_lastError;
};

/**
 * @brief Special token constants
 */
namespace SpecialTokens {
    constexpr int64_t PAD_TOKEN = 0;
    constexpr int64_t BOS_TOKEN = 1;  // Beginning of sequence
    constexpr int64_t EOS_TOKEN = 2;  // End of sequence
    
    // Speech tokens (from S3Tokenizer)
    constexpr int64_t START_SPEECH_TOKEN = 6561;
    constexpr int64_t STOP_SPEECH_TOKEN = 6562;
}

/**
 * @brief Text normalization utilities (matching Python's punc_norm)
 */
std::string NormalizeTextForTTS(const std::string& text);

} // namespace ChatterboxTTS
